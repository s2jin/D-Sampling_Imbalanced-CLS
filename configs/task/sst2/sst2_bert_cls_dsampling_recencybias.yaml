# @package _global_

#name: 'klue_tc-bert-cls'
name: ${datamodule.name}-${model.name}-${agent.name}-${agent.warmup}
version: 1

datamodule:
    name: 'sst2_cls'
    _target_: src.datamodule.${datamodule.name}.DataModule

    ## dataloader parameter
    batch_size: 128
    shuffle: False
    num_workers: 4

    ## data
    data_dir: 'data/sst2'
    train_data: 'training.jsonl' ## or 'data/klueTC_10shot/training.jsonl'
    valid_data: 'valid.jsonl'
    test_data: 'test.jsonl'
    label_file: 'label_list.txt'

    ## length limit
    check_length: False
    max_source_length: 96
    max_target_length: 0

model:
    name: 'bert_cls'
    _target_: src.models.${model.name}.Model
    path: 'bert-base-uncased'
    num_labels: 7 

tokenizer:
    name: 'bert'
    _target_: src.tokenizer.${tokenizer.name}.Tokenizer 
    path: 'bert-base-uncased'
    side: 'right'

optimizer:
    _target_: torch.optim.Adam
    lr: 1e-5

agent:
    name: 'dsampling_recencybias'
    _target_: src.agent.${agent.name}.Agent

    epochs: 50
    patience: 5
    warmup: 10

    model_all_save: false
    predict_after_all_training: false       # evaluate on test set, using best model
    predict_after_training: true       # evaluate on test set, using best model
